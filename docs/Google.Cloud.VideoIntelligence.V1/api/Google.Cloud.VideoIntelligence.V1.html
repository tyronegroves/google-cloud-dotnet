<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Namespace Google.Cloud.VideoIntelligence.V1
   | Google.Cloud.VideoIntelligence.V1 </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Namespace Google.Cloud.VideoIntelligence.V1
   | Google.Cloud.VideoIntelligence.V1 ">
    <meta name="generator" content="docfx 2.39.1.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="Google.Cloud.VideoIntelligence.V1">
  
  <h1 id="Google_Cloud_VideoIntelligence_V1" data-uid="Google.Cloud.VideoIntelligence.V1" class="text-break">Namespace Google.Cloud.VideoIntelligence.V1
  </h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>
    <h3 id="classes">Classes
  </h3>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.AnnotateVideoException.html">AnnotateVideoException</a></h4>
      <section><p>An error occurring when annotating an video.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.AnnotateVideoProgress.html">AnnotateVideoProgress</a></h4>
      <section><p>Video annotation progress. Included in the <code>metadata</code>
field of the <code>Operation</code> returned by the <code>GetOperation</code>
call of the <code>google::longrunning::Operations</code> service.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.AnnotateVideoRequest.html">AnnotateVideoRequest</a></h4>
      <section><p>Video annotation request.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.AnnotateVideoResponse.html">AnnotateVideoResponse</a></h4>
      <section><p>Video annotation response. Included in the <code>response</code>
field of the <code>Operation</code> returned by the <code>GetOperation</code>
call of the <code>google::longrunning::Operations</code> service.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.Entity.html">Entity</a></h4>
      <section><p>Detected entity from video analysis.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ExplicitContentAnnotation.html">ExplicitContentAnnotation</a></h4>
      <section><p>Explicit content annotation (based on per-frame visual signals only).
If no explicit content has been detected in a frame, no annotations are
present for that frame.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ExplicitContentDetectionConfig.html">ExplicitContentDetectionConfig</a></h4>
      <section><p>Config for EXPLICIT_CONTENT_DETECTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ExplicitContentFrame.html">ExplicitContentFrame</a></h4>
      <section><p>Video frame level annotation results for explicit content.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.FaceAnnotation.html">FaceAnnotation</a></h4>
      <section><p>Face annotation.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.FaceDetectionConfig.html">FaceDetectionConfig</a></h4>
      <section><p>Config for FACE_DETECTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.FaceFrame.html">FaceFrame</a></h4>
      <section><p>Video frame level annotation results for face detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.FaceSegment.html">FaceSegment</a></h4>
      <section><p>Video segment level annotation results for face detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.LabelAnnotation.html">LabelAnnotation</a></h4>
      <section><p>Label annotation.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.LabelDetectionConfig.html">LabelDetectionConfig</a></h4>
      <section><p>Config for LABEL_DETECTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.LabelFrame.html">LabelFrame</a></h4>
      <section><p>Video frame level annotation results for label detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.LabelSegment.html">LabelSegment</a></h4>
      <section><p>Video segment level annotation results for label detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.NormalizedBoundingBox.html">NormalizedBoundingBox</a></h4>
      <section><p>Normalized bounding box.
The normalized vertex coordinates are relative to the original image.
Range: [0, 1].</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.NormalizedBoundingPoly.html">NormalizedBoundingPoly</a></h4>
      <section><p>Normalized bounding polygon for text (that might not be aligned with axis).
Contains list of the corner points in clockwise order starting from
top-left corner. For example, for a rectangular bounding box:
When the text is horizontal it might look like:
   0----1
   |    |
   3----2</p>
<p>When it&apos;s clockwise rotated 180 degrees around the top-left corner it
becomes:
   2----3
   |    |
   1----0</p>
<p>and the vertex order will still be (0, 1, 2, 3). Note that values can be less
than 0, or greater than 1 due to trignometric calculations for location of
the box.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.NormalizedVertex.html">NormalizedVertex</a></h4>
      <section><p>A vertex represents a 2D point in the image.
NOTE: the normalized vertex coordinates are relative to the original image
and range from 0 to 1.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ObjectTrackingAnnotation.html">ObjectTrackingAnnotation</a></h4>
      <section><p>Annotations corresponding to one tracked object.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ObjectTrackingConfig.html">ObjectTrackingConfig</a></h4>
      <section><p>Config for OBJECT_TRACKING.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ObjectTrackingFrame.html">ObjectTrackingFrame</a></h4>
      <section><p>Video frame level annotations for object detection and tracking. This field
stores per frame location, time offset, and confidence.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ShotChangeDetectionConfig.html">ShotChangeDetectionConfig</a></h4>
      <section><p>Config for SHOT_CHANGE_DETECTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.SpeechContext.html">SpeechContext</a></h4>
      <section><p>Provides &quot;hints&quot; to the speech recognizer to favor specific words and phrases
in the results.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.SpeechRecognitionAlternative.html">SpeechRecognitionAlternative</a></h4>
      <section><p>Alternative hypotheses (a.k.a. n-best list).</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.SpeechTranscription.html">SpeechTranscription</a></h4>
      <section><p>A speech recognition result corresponding to a portion of the audio.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.SpeechTranscriptionConfig.html">SpeechTranscriptionConfig</a></h4>
      <section><p>Config for SPEECH_TRANSCRIPTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.TextAnnotation.html">TextAnnotation</a></h4>
      <section><p>Annotations related to one detected OCR text snippet. This will contain the
corresponding text, confidence value, and frame level information for each
detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.TextDetectionConfig.html">TextDetectionConfig</a></h4>
      <section><p>Config for TEXT_DETECTION.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.TextFrame.html">TextFrame</a></h4>
      <section><p>Video frame level annotation results for text annotation (OCR).
Contains information regarding timestamp and bounding box locations for the
frames containing detected OCR text snippets.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.TextSegment.html">TextSegment</a></h4>
      <section><p>Video segment level annotation results for text detection.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoAnnotationProgress.html">VideoAnnotationProgress</a></h4>
      <section><p>Annotation progress for a single video.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoAnnotationResults.html">VideoAnnotationResults</a></h4>
      <section><p>Annotation results for a single video.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoContext.html">VideoContext</a></h4>
      <section><p>Video context and/or feature-specific parameters.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceService.html">VideoIntelligenceService</a></h4>
      <section><p>Service that implements Google Cloud Video Intelligence API.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceService.VideoIntelligenceServiceBase.html">VideoIntelligenceService.VideoIntelligenceServiceBase</a></h4>
      <section><p>Base class for server-side implementations of VideoIntelligenceService</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceService.VideoIntelligenceServiceClient.html">VideoIntelligenceService.VideoIntelligenceServiceClient</a></h4>
      <section><p>Client for VideoIntelligenceService</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceClient.html">VideoIntelligenceServiceClient</a></h4>
      <section><p>VideoIntelligenceService client wrapper, for convenient use.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceClientBuilder.html">VideoIntelligenceServiceClientBuilder</a></h4>
      <section><p>Builder class for <a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceClient.html">VideoIntelligenceServiceClient</a> to provide simple configuration of credentials, endpoint etc.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceClientImpl.html">VideoIntelligenceServiceClientImpl</a></h4>
      <section><p>VideoIntelligenceService client wrapper implementation, for convenient use.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceSettings.html">VideoIntelligenceServiceSettings</a></h4>
      <section><p>Settings for a <a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoIntelligenceServiceClient.html">VideoIntelligenceServiceClient</a>.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.VideoSegment.html">VideoSegment</a></h4>
      <section><p>Video segment.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.WordInfo.html">WordInfo</a></h4>
      <section><p>Word-specific information for recognized words. Word information is only
included in the response when certain request parameters are set, such
as <code>enable_word_time_offsets</code>.</p>
</section>
    <h3 id="enums">Enums
  </h3>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.Feature.html">Feature</a></h4>
      <section><p>Video annotation feature.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.LabelDetectionMode.html">LabelDetectionMode</a></h4>
      <section><p>Label detection mode.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.Likelihood.html">Likelihood</a></h4>
      <section><p>Bucketized representation of likelihood.</p>
</section>
      <h4><a class="xref" href="Google.Cloud.VideoIntelligence.V1.ObjectTrackingAnnotation.TrackInfoOneofCase.html">ObjectTrackingAnnotation.TrackInfoOneofCase</a></h4>
      <section><p>Enum of possible cases for the &quot;track_info&quot; oneof.</p>
</section>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
             
            
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
